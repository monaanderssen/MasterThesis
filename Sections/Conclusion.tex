%\addcontentsline{toc}{chapter}{Conclusions and outlook}
\chapter{Conclusions and outlook}

\label{sec:Conclusion}

In this thesis we have been searching for Supersymmetry (SUSY) and Dark Matter (DM) using two Machine Learning (ML) based algorithms, namely Boosted Decision Trees (BDT) and Neural Networks (NN). We have also reproduced the results from some published work by the ATLAS collaboration \cite{sleptonexclusion, monoZexclusion}, which have searched for the same signal processes using a simple cut and count method. The results from the cut and count method are used to evaluate how well the ML methods performed by comparing the expected sensitivity. The BDT and NN were trained on different compositions of mass splittings (high, intermediate and low) and features/kinematical variables, and for four different signal processes (three SUSY and one DM). Both ML methods have overall performed very well and reached AUC-scores above 0.90 for every trained model. An AUC-score of 0.90 means that the ML methods are able to classify the signal as signal and background as background 90\% of the time. 

Looking at the achieved sensitivity of the three analysis methods and comparing them to each other it is clear that the ML methods overall have more sensitivity for the signals than the cut and count method,i n particular for low mass splittings, which is the experimentally challenging because it requires working with low $p_T$ leptons and lower $E_T^{miss}$. To achieve a high sensitivity for low mass splittings is difficult in the cut and count method and it is therefore very satisfying that the ML perform rather well for these signals. We can, with these results, conclude that ML may indeed be an efficient and rewarding technique when performing searches for new physics phenomena. 

For future research using these or similar ML methods, it would be interesting to see what we could have done to make the performance better. In this thesis we have used a couple of precuts, which made the ML methods somewhat biased and thus not able to learn everything from a less selective data input. It would be interesting to see how it would perform without these precuts and with more features included. However, this would imply more powerful computing infrastructure and more time to perform our analysis because of the massive datasets. 

It would also be interesting to do a hyper parameter scan to see which parameters are the best to use for our BDT and NN. However, although this way to perform a ML analysis is definitely very useful, the most preferable way would have been to make the ML method independent of a hypothesis. This can be done through a NN where we do a so-called \textit{anomaly detection}. Instead of training on MC-samples for both signal and background, we train only on background before we test with data. The network would then tell us if there is something interesting to see in the data or not. However, this introduces many new challenges. One of them is to know what we have actually found because there is no hypothesis to confirm. Unfortunately, today's ML algorithms are not complex enough to handle this problem, but this is going to be a very interesting research to follow in the future.







\begin{comment}


Konklusjon:
- ML mer sensitiv
- Si kort om hva som er gjort


Outlook:
- No precuts
- Hyperparameter s√∏k
- Anomaly detection
- Andre/flere features
- 


\end{comment}
